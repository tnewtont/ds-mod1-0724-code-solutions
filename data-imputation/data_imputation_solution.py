# -*- coding: utf-8 -*-
"""data-imputation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ARyd91_CVIlO8H0ncYhNWamQVX5yi1-x
"""

import pandas as pd
import numpy as np
from itertools import groupby
import random

"""Quiz 1. Handling null values in datasets is important because doing so ensures the quality of our analysis. Namely, we preserve the integrity of the dataset and reduce bias.

# **#1 Read titanic.csv into memory.**
"""

ti = pd.read_csv(r'/content/titanic.csv')
ti

"""# **#2 Impute the missing values in "Age" using the median age of all passengers and store the result in a column called "Age_med".**"""

# utilize .median
ti['Age_med'] = ti['Age'].transform(lambda x: x.fillna(x.median()))
ti['Age_med']

# Verifying that Age_med has no nulls
ti['Age_med'].isna().sum()

"""# **#3 Impute the missing values in "Age" using the mean age of passengers of the same sex and store the result in a column called "Age_mean_sex".**"""

# Let's group by sex
ti['Age_mean_sex'] = ti.groupby('Sex')['Age'].transform(lambda x: x.fillna(x.mean()))
ti['Age_mean_sex']

# Verify that Age_mean_sex has no nulls
ti['Age_mean_sex'].isna().sum()

"""# **#4 Impute the missing values in "Cabin" using a method of your choosing and store it in the original "Cabin" column.**"""

# Let's investigate the Cabin column
cab_test = ti['Cabin'].value_counts(dropna = False)
cab_test
#def flatten_list(nested_list):
    #return list(itertools.chain(*nested_list))

cabins_cleaned = ti['Cabin'].dropna() # Get rid of nulls first
cabins_split = cabins_cleaned.tolist() # Convert to list
cabins_split = [i.split(' ', 1)[0] for i in cabins_split] # This will split apart entries that have multiple cabins listed together

len(cabins_split) # There are 204 individual cabin classes total

# Extract only the letters now
cabins_split_letter = []
for c in cabins_split:
  cabins_split_letter.append(c[0])

# Initialize a dictionary where the keys are the letters, and the values are lists
# containing the cabin classes of each respective leetter

cabin_group = {}
for cabin in cabins_split:
  cabin_group.setdefault(cabin[0],[]).append(cabin)

cabin_group

cabins_list = list(cabin_group.values()) # Get each group of cabins as a list

cabins_letters = list(cabin_group.keys()) # Get the letters as a list

cabins_letters_sorted = sorted(cabins_letters) # Sort cabins_letters
cabins_letters_sorted

cabins_list_sorted = sorted(cabins_list) # Sort cabins_list
cabins_list_sorted

for c in cabins_list_sorted: # Get the counts for each letter
  print(c[0][0],len(c))

# From earlier, the total number of individual cabin classes is 204
# We'll create a list of the weights for each letter

letter_weights = []
for c in cabins_list_sorted:
  letter_weights.append(len(c)/204)

letter_weights

# Utilize cabin_letters_sorted with weights
# Create a dictionary of letters to weights
# Turns out I didn't need this, but I just created it in case
letter_weights_dict = dict(zip(cabins_letters_sorted, letter_weights))

# Remove all numbers, obtain only the letters, but leave NaN's untouched
cabins_let_only = ti['Cabin'].apply(lambda x: x if x is np.nan else str(x)[0].upper()) # Use np.nan!

# We now obtain only the letters, including NaN's
cabins_let_only

# Impute the NaN's by doing a weighted sampling
# I used random.choices since each letter has its own weight, and I'm using ''.join since random.choices returns a list,
# which we need to convert to an individual string

cabins_let_only_imp = cabins_let_only.map(lambda x: ''.join(random.choices(population = cabins_letters_sorted, weights = letter_weights, k = 1)) if x != x else x)

cabins_let_only_imp

# Checking the new counts for each letter
cabins_let_only_imp.value_counts()

# Set ti['Cabin'] to cabins_let_only_imp
ti['Cabin'] = cabins_let_only_imp