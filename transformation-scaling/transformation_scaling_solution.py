# -*- coding: utf-8 -*-
"""transformation-scaling

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15LpizP53v35ZpGhc8OU70TAUP7-Dbicm
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler, normalize

"""Robust: use when there are outliers

Max absolute: use when there are a lot of zeros in the data

Min-max: when you know the true population min and max of the data and it's equal to the sample min and max of the data (if through the domain knowledge, you know the range of the data)

Standard scaler: if you want the data to be normally-distributed or centered at 0

Note: you're not guaranteed to get normal distributions afterwards!

normalization is on rows (the magnitude is 1)
L1 =  sum of absolute values
L2 = magnitude equals 1

sklearn.preprocessing --> normalize

# **Quiz**

1. The robust method is best when there are many outliers.
2. The standard scaler method produces data that is normally distributed. The mean is 0 and variance of 1.
3. The max-absolute method does not remove sparsity, which is when a large percentage of the data is missing or zero.
4. The min-max method is ideal if the data is known via domain knowledge.

# **#1 Use the most appropriate scaling technique for each variable to scale disp, hp, drat, and wt, assuming wt should be normally distributed and the true bounds are known for disp.**
"""

mtcars = pd.read_csv(r'/content/mtcars_mod.csv')
mtcars

# Scaling disp
# Since the true bounds of disp are known, let's try min-max

disp_col = mtcars[['disp']]

scaler_minmax = MinMaxScaler()
scaler_minmax.fit(disp_col)
vals_minmax = scaler_minmax.transform(disp_col)

# Scaling hp
# hp has many zeros, so let's try max-absolute
hp_col = mtcars[['hp']]

scaler_maxabs = MaxAbsScaler()
scaler_maxabs.fit(hp_col)
vals_maxabs = scaler_maxabs.transform(hp_col)

# Scaling drat
# drat has some outliers, so try robust
drat_col = mtcars[['drat']]

scaler_rob = RobustScaler()
scaler_rob.fit(drat_col)
vals_rob = scaler_rob.transform(drat_col)

# Scaling wt
# Let's use standard scaler
wt_col = mtcars[['wt']]

scaler_ss = StandardScaler()
scaler_ss.fit(wt_col)
vals_ss = scaler_ss.transform(wt_col)

# To put back to original dataframe, df.loc(:, whatever the numeric columns are equals that array)

"""# **#2 Use Box-Cox or Yeo-Johnson to determine the best transformation to use to make mpg and qsec normally distributed. Show the transformed data and the value of $\lambda$.**"""

from scipy.stats import yeojohnson

#mpg, which has positive values
mpg_yj, mpg_lambda = yeojohnson(mtcars['mpg'])

plt.hist(mpg_yj)

mpg_yj_df = pd.DataFrame(mpg_yj, columns = ['mpg'])
mpg_yj_df

mpg_lambda

#qsec, which has positive and negative values
qsec_yj, qsec_lambda = yeojohnson(mtcars['qsec'])

plt.hist(qsec_yj)

qsec_yj_df = pd.DataFrame(qsec_yj, columns = ['qsec'])
qsec_yj_df

qsec_lambda

"""# **#3 Normalize all of the numeric rows using L2-normalization and display the new dataframe.**"""

# Get all the numeric columns only
mtcars_num_only = mtcars.iloc[:,1:]
mtcars_num_only

# Obtain column names from extracted dataframe
colnames = list(mtcars_num_only.columns)

# By default normalize() performs L2
l2_norm = normalize(mtcars_num_only)

# Convert to dataframe
l2_norm_df = pd.DataFrame(l2_norm, columns = colnames)
l2_norm_df